{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple\n",
    "from scipy import stats\n",
    "import dexplot as dxp\n",
    "import scipy.stats as ss\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = pathlib.Path('./data')\n",
    "RESULTS_PATH = pathlib.Path('./results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH / 'accepted_2007_to_2018Q4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_list = ['addr_state', 'annual_inc', 'application_type', \n",
    "             'dti', 'earliest_cr_line', 'emp_length', \n",
    "             'emp_title', 'fico_range_high', 'fico_range_low', \n",
    "             'grade', 'home_ownership', 'id', 'initial_list_status', \n",
    "             'installment', 'int_rate', 'issue_d', 'loan_amnt', \n",
    "             'mort_acc', 'open_acc', 'pub_rec', 'pub_rec_bankruptcies', \n",
    "             'purpose', 'revol_bal', 'revol_util', 'sub_grade', 'term', \n",
    "             'title', 'total_acc', 'verification_status', 'zip_code', 'loan_status']\n",
    "keep_list.sort()\n",
    "df = df[keep_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['loan_status'].isin(['Fully Paid', 'Charged Off'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = 1\n",
    "df['target'] = (df['target'].where(df['loan_status'] == 'Charged Off', 0))\n",
    "df = df.drop('loan_status', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df.select_dtypes(include=['float64', 'int64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_cols = ['earliest_cr_line', 'issue_d']\n",
    "for c in dates_cols:\n",
    "    df[c] = pd.to_datetime(df[c], format='%b-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df.select_dtypes('object').columns"
   ]
  },
  {
   "source": [
    "# Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Let's start with some preprocessing now that we have some understanding of the data.\n",
    "\n",
    "We need to start filling the missing values.\n",
    "\n",
    "For numerical columns, for simplicity, we are going to fill missing values with the median.\n",
    "For categorical columns, a simple approach would be to fill the missing values with the most common observation.\n",
    "\n",
    "Keep in mind that these approaches are just to keep things simple. If one thinks that more time should be spent on preprocessing, they could go with fancier methods, including:\n",
    "- using other ML models to come up with values for the missing \n",
    "\n",
    "When filling the missing values, it is important that we calculate this value using the training set only, and then use the same value for the test set\n",
    "so as to avoid data leakage from the training set to the test set."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2013, 2014, 2015, 2016]\n",
    "train_years = years[0:3]\n",
    "test_years = years[3:]\n",
    "train_df = df[df['issue_d'].dt.year.isin(train_years)]\n",
    "test_df = df[df['issue_d'].dt.year.isin(test_years)]"
   ]
  },
  {
   "source": [
    "# Filling Missing Values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "print(\"Missing Percentage\")\n",
    "for col in df.columns:\n",
    "    missing_percentage = 100 - 100*df[col].count()/len(df)\n",
    "    if missing_percentage > 0:\n",
    "        print(col + \" \" + str())\n",
    "        print(missing_percentage)\n",
    "        print(df[col].dtype)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Missing Percentage\n",
      "dti \n",
      "0.027800283949417803\n",
      "float64\n",
      "emp_length \n",
      "5.835903992388367\n",
      "object\n",
      "emp_title \n",
      "6.376597215511666\n",
      "object\n",
      "mort_acc \n",
      "3.5145059503014124\n",
      "float64\n",
      "pub_rec_bankruptcies \n",
      "0.05180962008756751\n",
      "float64\n",
      "revol_util \n",
      "0.0637027896915896\n",
      "float64\n",
      "title \n",
      "1.23830195270979\n",
      "object\n",
      "zip_code \n",
      "7.433231002096363e-05\n",
      "object\n"
     ]
    }
   ]
  },
  {
   "source": [
    "A simple approach for numerical features: Fill with the median\n",
    "\n",
    "For categorical features we can fill with the most frequent values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df, num_cols, cat_cols):\n",
    "\n",
    "    for col in num_cols:\n",
    "        median = df[col].median()\n",
    "        df[col] = df[col].fillna(median)\n",
    "\n",
    "    for col in cat_cols:\n",
    "        most_common = df[col].mode()[0]\n",
    "        df[col] = df[col].fillna(most_common)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Remark: the training and test medians might not be exactly the same, so the values filled would be different\n",
    "# This also applies to the most common observation, which may be different in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALERS = {}\n",
    "LABEL_ENCODERS = {}"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df, num_cols, cat_cols, log_cols, is_train=True):\n",
    "    ''' This function will be used to take the log of our features, scale our features, encodings, etc.'''\n",
    "\n",
    "    # taking the log of features in log_cols\n",
    "    # a problem is that at least one feature has neg values, so we are going to drop those rows\n",
    "    df = df[df['dti'] > -1]\n",
    "\n",
    "    for col in log_cols:\n",
    "        df[col] = np.log1p(df[col])\n",
    "    \n",
    "    # not every model requires feature scaling but some do\n",
    "    # let's scale the numerical features with robustscaler\n",
    "    for col in num_cols:\n",
    "        scaler = RobustScaler()\n",
    "        if is_train:\n",
    "            scaler.fit_transform(df[col])\n",
    "            SCALERS[col] = scaler\n",
    "        else:\n",
    "            SCALERS[col].transform(df[col])\n",
    "\n",
    "\n",
    "     # TODO: feature engineering for emp_length\n",
    "\n",
    "     cat_cols.remove('emp_length')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for col in cat_cols:\n",
    "        scaler = LabelEncoder()\n",
    "        if is_train:\n",
    "            scaler.fit_transform(df[col])\n",
    "            SCALERS[col] = scaler\n",
    "        else:\n",
    "            SCALERS[col].transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(train_df['addr_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 'C'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/ds/ds_test/env/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36m_encode_python\u001b[0;34m(values, uniques, encode)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ds/ds_test/env/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'C'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-1142c2300099>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'grade'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ds/ds_test/env/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ds/ds_test/env/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, encode)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"argument must be a string or number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ds/ds_test/env/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36m_encode_python\u001b[0;34m(values, uniques, encode)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             raise ValueError(\"y contains previously unseen labels: %s\"\n\u001b[0;32m---> 67\u001b[0;31m                              % str(e))\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: 'C'"
     ]
    }
   ],
   "source": [
    "le.transform(df['grade'].head())"
   ]
  },
  {
   "source": [
    "For categorical features, we can fill with the most common value."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    Teacher\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "log_cols = [\n",
    "    'annual income',\n",
    "    'dti',\n",
    "    'installment',\n",
    "    'int_rate',\n",
    "    'loan_amnt',\n",
    "    'open_acc',\n",
    "    'revol_bal',\n",
    "    'revol_util',\n",
    "    'total_acc'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0     523837\n",
       "1.0     226135\n",
       "2.0     188941\n",
       "3.0     139381\n",
       "4.0      94920\n",
       "5.0      57632\n",
       "6.0      32539\n",
       "7.0      16850\n",
       "8.0       8378\n",
       "9.0       4285\n",
       "10.0      2197\n",
       "11.0      1206\n",
       "12.0       640\n",
       "13.0       356\n",
       "14.0       244\n",
       "15.0       132\n",
       "16.0        93\n",
       "17.0        61\n",
       "18.0        48\n",
       "19.0        29\n",
       "20.0        25\n",
       "24.0        16\n",
       "21.0        14\n",
       "22.0        14\n",
       "23.0        10\n",
       "25.0         9\n",
       "27.0         8\n",
       "26.0         6\n",
       "28.0         4\n",
       "29.0         4\n",
       "34.0         3\n",
       "30.0         2\n",
       "32.0         2\n",
       "37.0         2\n",
       "31.0         2\n",
       "51.0         1\n",
       "47.0         1\n",
       "36.0         1\n",
       "35.0         1\n",
       "Name: mort_acc, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "df['mort_acc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "loop of ufunc does not support argument 0 of type str which has no callable log1p method",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'log1p'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-3d174b25ef43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dti'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: loop of ufunc does not support argument 0 of type str which has no callable log1p method"
     ]
    }
   ],
   "source": [
    "np.log1p(df[df['dti']==-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "addr_state                               AK\n",
       "annual_inc                                0\n",
       "application_type                 Individual\n",
       "dti                                      -1\n",
       "earliest_cr_line        1934-04-01 00:00:00\n",
       "fico_range_high                         629\n",
       "fico_range_low                          625\n",
       "grade                                     A\n",
       "home_ownership                          ANY\n",
       "initial_list_status                       f\n",
       "installment                            4.93\n",
       "int_rate                               5.31\n",
       "issue_d                 2007-06-01 00:00:00\n",
       "loan_amnt                               500\n",
       "mort_acc                                  0\n",
       "open_acc                                  0\n",
       "pub_rec                                   0\n",
       "pub_rec_bankruptcies                      0\n",
       "purpose                                 car\n",
       "revol_bal                                 0\n",
       "revol_util                                0\n",
       "sub_grade                                A1\n",
       "term                              36 months\n",
       "total_acc                                 2\n",
       "verification_status            Not Verified\n",
       "target                                    0\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "df.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}